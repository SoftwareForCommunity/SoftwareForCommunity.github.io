---
layout: post
title: TEST POST"
date: 2017-12-05 10:40:00 -0500
categories: machine learning algorithms
---

# {{page.title}}

*Genetic algorithms are a form of machine learning based on the principles of natural selection, but are frequently treated as a black box by third-party software packages. This post outlines the development of the first iteration of our own genetic algorithm.*

### Guiding principles

<a href="https://en.wikipedia.org/wiki/Genetic_algorithm">Genetic algorithms</a> are effective at solving certain optimization problems. Rather than trawl along gradients in the search space these algorithms search for solutions in a semi-random manner that borrows from notions of population dynamics in biology. Every genetic algorithm has two components; the fitness function and the iteration routine. The fitness function is the function we seek to optimize, modulo constraints (penalties). The fitness function takes as input a potential solution and outputs a score. The iteration routine is where this class of algorithms gets its name. New solutions are generated by crossbreeding and mutating the top solutions, and the program avoids backtracking by carrying the top scores from generation to generation. We'll be designing our algorithm in R.

## Algorithm Blueprint

Many concepts in standard optimization theory have biological counterparts. For example, an algorithm getting stuck in a local minima or maxima is analogous to a lack of genetic diversity in a population (most or all viable solutions lie in the same range). Here we explore the design of our algorithm. The full code is at the bottom of the article.

### Exit Conditions

As the way the algorithm travels through the search space is random it's not guaranteed to converge to a solution (or even the same solution) when it is run. Therefore we want a way to terminate the algorithm when a reasonable condition (or set of conditions) have been met. In our algorithm we have three exit conditions: the maximum number of iterations (or generations), the maximum allowable run time, and the maximum number of consecutive generations without a gain in fitness. However, we want to allow some time for the model to find an initial solution, which we call the burn in period, where we won't check for stagnation. Therefore we can write our iteration as a while loop, as seen below.

```R
while(iterations < maxIterations && (currentTime - startTime) < maxTime && populationStagnationIndex < populationStagnationCap) {}
```

### Data Structure of our Solutions

The nature of the solution depends on the fitness function we seek to evaluate. For our test functions the solutions will be an array of real numbers. We can therefore bundle our population of solutions (the entire set of solutions in a single generation) in a 2D array of real numbers. The makeup of the population from one generation to the next is determined by the algorithm's author. Each generation of our population is made up of four components: the top individuals from the previous generation (elitist selection), crossbreeding between the best individuals, mutated copies of the top solutions, and new random solutions that introduce 'genetic diversity' to the population (random immigrants). The distribution of these components within a population is variable, but as a default we set elitist selection to $$\frac{1}{16}$$, cross-over to $$\frac{3}{16}$$, mutation to $$\frac{1}{2}$$, and random immigrants to $$\frac{1}{4}$$.

Within a population, a single solution and all data accompanying it is an individual. The solution data itself is a chromosome, and the actual data within the solution are the genes.

#### Cross Over

Cross over can be achieved in a variety of ways. The simplest is one point cross over. Consider two chromosomes, $$x = \{A, A, C, T, G\}$$ and $$y = \{1, 2, 1, 3, 4\}$$. With one point cross over we pick an index, say 3, and every gene after position 3 in the chromosome is flipped giving us $$x = \{A, A, C, 3, 4\}$$ and $$y = \{1, 2, 1, T, G\}$$. In our algorithm we use two point cross over, which picks a section 'in the middle' of a chromosome and flips it between two genes (leaving the heads and tails the same).

```R
#Cross-Breed the top solutions using two-point cross-over
for(i in seq(1, numberCrossOvers, 2)) {
  points = sample(1:numberOfGenes,2)
  #Set new genes for Chromosome i
  populationNew[(i+numberElitists),] = populationOld[i,]
  populationNew[(i+numberElitists), points[1]:points[2]] = populationOld[i+1,points[1]:points[2]]
  #Set new genes for Chromosome i+1
  populationNew[(i+numberElitists+1),] = populationOld[i+1,]
  populationNew[(i+numberElitists+1), points[1]:points[2]] = populationOld[i,points[1]:points[2]]
}
```

#### Mutation

Mutation randomly changes 1 or more genes in the chromosome with some probability greater than zero. For instance, in passing from generation $$n$$ to generation $$n+1$$ the chromosome $$x$$ might change from $$\{A, A, C, T, G\}$$ to $$\{A, C, C, T, G\}$$. In our algorithm we mutate every gene once in the top half of the previous generation. Since we have elitist selection, there's no gain to be had by making the mutation probability for a single gene to be anything less than one, and constant mutation of the solutions results in greater genetic diversity.

```R
for(i in 1:numberMutatedChromosomes) {
  mutationIndex = sample(1:numberOfGenes, mutationRate) #Randomly select the gene(s) which will be mutated
  populationOld[i,mutationIndex] = runif(1,-1,1)
  populationNew[(i + numberElitists + numberCrossOvers),] = populationOld[i,]
}
```

## Test Fitness Functions

### Sphere Function

The <a href="https://en.wikipedia.org/wiki/Test_functions_for_optimization">sphere function</a> is one of the simplest optimization test cases. It has a local minima at zero in all dimensions, and is smooth. For $$n$$ dimensions the sphere function is

$$
\sum_{i = 1}^n x_i^2.
$$

<img src="/assets/images/xSQySQ.png" alt = "Sphere function plot" width="600" height="450">

### A Noisy Cosine Function

Consider the function

$$
\left| \sum_{i = 1}^n x_i \cos(2x_i)\right|,
$$

which can be presented graphically as follows:

<img src="/assets/images/xCos(2x).png" alt = "Cosine function plot" width="600" height="450">

While this is smooth from the perspective of differentiability, it is very noisy from a numerical perspective and problems like this present a challenge for global optimization routines. Our function will tend to find a local minima very close to the global minima, but the oscillation around the true minimum means that it usually won't find a solution of all zeros.

### Test Function Convergence

The convergence of our algorithm for the test functions is plotted below, with one sample set of solutions for each fitness function. The vertical scale is the (natural) log inverse of the fitness score, which is just the output of the fitness function, so a height of 15 on the chart represents a score of $$\frac{1}{e^{15}}$$. We can see that our algorithm has a tougher time with the cosine function as it takes longer to find a new optimal solution (a result which is borne out by repeatedly running the algorithm). However, our algorithm finds a pretty good solution to both test functions fairly quickly.

<img src="/assets/images/TestFunctionConvergence.png" alt = "Test function convergence" width="600" height="450">

## What This Means and Where We're Going

This quick introduction demonstrates some of the strengths and weaknesses of genetic algorithms. In general, these algorithms are good when you want to find a decent solution in the face of noisy data, but aren't optimal when you want to find the absolute best solution within large or complexly constrained solution spaces. However, when the problem is difficult to define and solve using standard differential methods genetic algorithms offer a powerful alternative.
